# Semantic RAG Pipeline Configuration - RAGAS 0.3.0 Compatible
# ================================================================

# Experiment Configuration
experiment:
  name: "semantic_rag_pipeline"
  description: "Semantic graph traversal RAG system with RAGAS 0.3.0 question generation"
  version: "1.0.0"
  tags: ["semantic_chunking", "graph_traversal", "rag", "ragas"]

# System Configuration
system:
  device: "auto"  # auto, cpu, cuda, mps
  max_memory_gb: 8
  min_disk_space_gb: 5
  num_workers: 4

# Directory Structure
directories:
  data: "data"
  embeddings: "embeddings"
  visualizations: "visualizations"
  logs: "logs"
  configs: "configs"

# Logging Configuration
logging:
  level: "INFO"
  log_to_file: true
  log_to_console: true
  max_log_file_mb: 100
  backup_count: 5

# Pipeline Execution
execution:
  mode: "full_pipeline"
  skip_phases: []
  force_recompute: []

# Models Configuration
models:
  embedding_models:
    - "sentence-transformers/all-mpnet-base-v2"
    - "sentence-transformers/all-MiniLM-L6-v2"
  embedding_batch_size: 32
  embedding_cache: true

# Wikipedia Configuration
wikipedia:
  use_cached_articles: true
  topics:
    - "Machine learning"

  articles_per_topic: 1
  max_article_length: 5000000
  min_article_length: 1000
  language: "en"
  rate_limit_delay: 1.0
  retry_attempts: 3
  timeout_seconds: 30

# Text Processing
text_processing:
  clean_html: true
  remove_references: true
  remove_navigation: true
  remove_tables: true
  fix_encoding: true
  normalize_whitespace: true
  min_sentence_length: 10
  max_sentence_length: 500

# Chunking Configuration
chunking:
  strategy: "sliding_window"
  window_size: 3
  overlap: 1

# Retrieval Configuration
retrieval:
  algorithm: "semantic_traversal"
  cache_graphs: true

  semantic_traversal:
    num_anchors: 3
    max_hops: 3
    similarity_threshold: 0.3
    max_results: 10

  baseline_vector:
    top_k: 10
    similarity_threshold: 0.5

# Similarity Matrix Configuration
similarities:
  use_cached: true
  similarity_metric: "cosine"
  intra_document:
    enabled: true
    top_k: 10
  inter_document:
    enabled: true
    top_x: 5
  batch_size: 1000
  max_memory_gb: 4

# Knowledge Graph Configuration
knowledge_graph:
  # Sparsity controls for efficient graph construction
  sparsity:
    relationship_limits:
      entity_similarity: 10      # Top-k entity-based relationships per node
      thematic_similarity: 5     # Top-k theme-based relationships per node
      embedding_similarity: 15   # Top-k embedding-based relationships per node
    min_thresholds:
      entity_similarity: 0.3     # Minimum Jaccard similarity for entity relationships
      thematic_similarity: 0.6   # Minimum theme overlap for thematic relationships
      embedding_similarity: 0.5  # Minimum cosine similarity for embedding relationships

  # Extractor configuration
  extractors:
    ner:
      enabled: true
      entity_types: ["PERSON", "ORG", "GPE", "MISC"]
    keyphrases:
      enabled: true
      max_features: 20
    themes:
      enabled: true
      max_themes: 5
    summary:
      enabled: true
      max_sentences: 2

# RAGAS Question Generation Configuration
questions:
  # Model configuration for RAGAS
  model:
    llm: "gpt-3.5-turbo"           # LLM for question generation
    embeddings: "text-embedding-ada-002"  # Embedding model for RAGAS
    temperature: 0.1               # Lower temperature for more consistent questions

  # Question generation parameters
  total_questions: 50              # Total questions to generate

  # Question type distribution (weights should sum to 1.0)
  distribution:
    single_hop: 0.4               # Simple factual questions (favor baseline)
    multi_hop_specific: 0.3       # Multi-hop specific questions (favor traversal)
    multi_hop_abstract: 0.3       # Multi-hop abstract questions (favor traversal)

  # Persona configuration (automatically created for AI/ML domain)
  personas:
    enabled: true
    auto_generate: true           # Use built-in personas for AI/ML research
    custom_personas: []           # Add custom personas if needed

  # RAGAS transforms configuration
  transforms:
    headlines:
      enabled: true
      max_num: 10                 # Max headlines to extract per document
    keyphrases:
      enabled: true
      max_num: 15                 # Max keyphrases to extract per document
    summary:
      enabled: true
    embedding:
      enabled: true               # Extract embeddings for similarity

  # Quality control
  validation:
    min_question_length: 10
    max_question_length: 200
    require_reference_context: true

# Dataset Generation (legacy - now uses RAGAS questions)
datasets:
  use_cached: true
  generation_method: "ragas"      # Use RAGAS for question generation

  # RAGAS Configuration (legacy compatibility)
  ragas:
    num_questions: 50
    question_types: ["factual", "reasoning", "multi_context"]
    difficulty_levels: ["easy", "medium", "hard"]

  # Custom Configuration (fallback only)
  custom:
    num_questions: 20
    focus_areas:
      - "conceptual_relationships"
      - "multi_hop_reasoning"
      - "contextual_understanding"
      - "reading_flow"
    semantic_bias: 0.7

  # Quality Control
  validation:
    min_answer_length: 50
    max_answer_length: 500
    require_multiple_chunks: true
    manual_validation_sample: 0.1

# Evaluation Configuration
evaluation:
  include_ragas_metrics: true
  include_custom_metrics: true
  include_baseline_comparison: true

# Visualization Configuration
visualization:
  enabled: true
  similarity_matrices: true
  traversal_paths: true
  chunk_boundaries: true
  question_distribution: true     # Visualize question type distribution

# Output Configuration
output:
  create_report: true
  export_data: true
  save_models: false
  include_question_analysis: true  # Include question generation analysis

# Cleanup Configuration
cleanup:
  remove_temp_files: false
  compress_large_files: true

# Notifications
notifications:
  enabled: false